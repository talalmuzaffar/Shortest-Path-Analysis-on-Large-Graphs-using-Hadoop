{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOF7eC9E-KdG"
      },
      "source": [
        "**Mounting the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV_MSKoXJDyk",
        "outputId": "fa09ed7a-b95a-4338-f940-578857618551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvOMAGyi-RP7"
      },
      "source": [
        "### Reading Files from the txt file which is tab sperated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZJTmZMXMB3ff"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import time\n",
        "\n",
        "filename = \"/content/drive/MyDrive/datasets/A2.txt\"\n",
        "\n",
        "adj_list = {} # Create an empty dictionary to hold the adjacency list\n",
        "\n",
        "with open(filename, \"r\") as f: # Read in the data from the input file\n",
        "    reader = csv.reader(f, delimiter=\"\\t\")\n",
        "    for i in range(4): # skip first four rows\n",
        "        next(reader)\n",
        "    for row in reader:\n",
        "        source, target = int(row[0]), int(row[1]) # Extract the source and target vertices from the row\n",
        "        if source not in adj_list: # If the source vertex isn't in the dictionary yet, add it\n",
        "            adj_list[source] = []\n",
        "        adj_list[source].append(target) # Add the target vertex to the source vertex's list of neighbors\n",
        "        if target not in adj_list: # If the target vertex isn't in the dictionary yet, add it\n",
        "            adj_list[target] = []\n",
        "        adj_list[target].append(source) # Add the source vertex to the target vertex's list of neighbors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh6kHZem-fi-"
      },
      "source": [
        "### BFS Algorithim for finding all the shortest paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXxtq-lI-xlk"
      },
      "source": [
        "This algorithim works by visitng the nearest neighnours of the source nodes and then keeps on moving far away in search of visiting other neighbours and shortest paths. \n",
        "\n",
        "We tried using other algorithim such as A* and Dijkstra but there very certain problems with them such as for A* cost of calculating Heuristic was high and other algorithims were not meant for unweighted graphs. Our best bet was BFS as It works best for large graphs. We modified it a little bit as we needed shortest paths.\n",
        "\n",
        "The Big'O time complexity of this code is O(V+E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3-zy2LGU-eV2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def bfs_shortest_paths(graph, start):\n",
        "    queue = [(start, [start], 0)] # [(StartingNode,[Path of Starting Node],Cost/Length of Starting Node)]\n",
        "    front = 0 # Pointer Front\n",
        "    rear = 1 # Pointer Back\n",
        "    visited = set([start]) \n",
        "    paths = {start: [start]} # Dictionary Maintaing Paths from StartNode(709) to every other node\n",
        "    path_lengths = {start: 0} # Lengths of Path\n",
        "    while front < rear: # Until List is not empty\n",
        "        node, path, length = queue[front] #1,[1],0 for the first ietration\n",
        "        front += 1 # Moving the pointer to the next element in the queue/list\n",
        "        for neighbor in graph[node]: # We will use this loop to traverse all the neighbours and add them to the list\n",
        "            if neighbor not in visited: # If neighbour is already not visited then add \n",
        "                visited.add(neighbor) \n",
        "                new_length = length + 1 # Increase the length by 1 because we have covered distance of one 709-->n1\n",
        "                if neighbor not in path_lengths or new_length < path_lengths[neighbor]: \n",
        "                    path_lengths[neighbor] = new_length\n",
        "                    paths[neighbor] = path + [neighbor]\n",
        "                    queue.append((neighbor, path + [neighbor], new_length))\n",
        "                    rear += 1\n",
        "\n",
        "    with open(f'{start}_shortest_paths.csv', 'w') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        for target in paths:\n",
        "            if target != start:\n",
        "                writer.writerow([start, target, ','.join(str(x) for x in paths[target])])\n",
        "    print(f'Shortest paths written to {start}_shortest_paths.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nbDtPOkBWfo",
        "outputId": "67610545-6db7-4f8d-ef10-34fb4222fefb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shortest paths written to 709_shortest_paths.csv\n",
            "Elapsed time for First Source: 39.2151 seconds\n",
            "Shortest paths written to 2653_shortest_paths.csv\n",
            "Elapsed time for Second Source: 35.2663 seconds\n",
            "Shortest paths written to 847_shortest_paths.csv\n",
            "Elapsed time for Third Source: 40.3230 seconds\n"
          ]
        }
      ],
      "source": [
        "#Path for First Source\n",
        "start_time = time.time()\n",
        "bfs_shortest_paths(adj_list, 709)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time for First Source: {elapsed_time:.4f} seconds\")\n",
        "\n",
        "# Paths for Second Source\n",
        "start_time = time.time()\n",
        "bfs_shortest_paths(adj_list, 2653)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time for Second Source: {elapsed_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "# Paths for Third Source\n",
        "start_time = time.time()\n",
        "bfs_shortest_paths(adj_list, 847)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Elapsed time for Third Source: {elapsed_time:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQpKBqn2_kIE"
      },
      "source": [
        "### Calculating the size of the files created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmhujltgCBJ5",
        "outputId": "7390bc87-a2fc-4334-d593-af83d8464a94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of 709_shortest_paths.csv file: 96.27 MB\n",
            "Size of 2653_shortest_paths.csv file: 97.02 MB\n",
            "Size of 847_shortest_paths.csv file: 108.08 MB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Finding the size of 709_shortest_paths.csv file\n",
        "size_in_bytes = os.path.getsize('709_shortest_paths.csv')\n",
        "size_in_kb = size_in_bytes / 1024\n",
        "size_in_mb = size_in_kb / 1024\n",
        "print(f\"Size of 709_shortest_paths.csv file: {size_in_mb:.2f} MB\")\n",
        "\n",
        "# Finding the size of 2653_shortest_paths.csv file\n",
        "size_in_bytes = os.path.getsize('2653_shortest_paths.csv')\n",
        "size_in_kb = size_in_bytes / 1024\n",
        "size_in_mb = size_in_kb / 1024\n",
        "print(f\"Size of 2653_shortest_paths.csv file: {size_in_mb:.2f} MB\")\n",
        "\n",
        "# Finding the size of 847_shortest_paths.csv file\n",
        "size_in_bytes = os.path.getsize('847_shortest_paths.csv')\n",
        "size_in_kb = size_in_bytes / 1024\n",
        "size_in_mb = size_in_kb / 1024\n",
        "print(f\"Size of 847_shortest_paths.csv file: {size_in_mb:.2f} MB\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
